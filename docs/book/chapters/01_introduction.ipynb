{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction\n",
    "\n",
    "## The Challenge of Phonetic Distance\n",
    "\n",
    "Historical linguists have long recognized that sound changes follow regular patterns. When Latin *pater* became Spanish *padre* and French *père*, the initial [p] remained unchanged, but when Latin *caput* became Spanish *cabo* and French *chef*, dramatic changes occurred. Understanding these changes requires a way to measure how \"different\" two sounds are from each other.\n",
    "\n",
    "Consider these cognate sets from Indo-European languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cognate sets showing sound correspondences\n",
    "cognates = {\n",
    "    'FATHER': {\n",
    "        'English': ['f', 'ɑː', 'ð', 'ər'],\n",
    "        'German': ['f', 'aː', 't', 'ər'],\n",
    "        'Latin': ['p', 'a', 't', 'er'],\n",
    "        'Sanskrit': ['p', 'i', 't', 'ar']\n",
    "    },\n",
    "    'FOOT': {\n",
    "        'English': ['f', 'ʊ', 't'],\n",
    "        'German': ['f', 'uː', 's'],\n",
    "        'Latin': ['p', 'eː', 'd'],\n",
    "        'Greek': ['p', 'o', 'd']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display the cognates\n",
    "for gloss, words in cognates.items():\n",
    "    print(f\"\\n{gloss}:\")\n",
    "    for lang, segments in words.items():\n",
    "        print(f\"  {lang:10} {''.join(segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Phonetic Features Matter\n",
    "\n",
    "The pattern above illustrates Grimm's Law: Proto-Indo-European \\*p became Germanic f. But why is this change \"natural\"? The answer lies in phonetic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfeat import phoneme_to_features, calculate_distance\n",
    "\n",
    "# Compare features of p and f\n",
    "p_features = phoneme_to_features('p')\n",
    "f_features = phoneme_to_features('f')\n",
    "\n",
    "# Find common and different features\n",
    "common_features = []\n",
    "different_features = []\n",
    "\n",
    "for feature in p_features:\n",
    "    if p_features[feature] == f_features[feature]:\n",
    "        if p_features[feature] == 1:  # Only show active features\n",
    "            common_features.append(feature)\n",
    "    else:\n",
    "        different_features.append(f\"{feature}: p={p_features[feature]}, f={f_features[feature]}\")\n",
    "\n",
    "print(\"Common features (both sounds share):\")\n",
    "for feat in common_features[:5]:  # Show first 5\n",
    "    print(f\"  + {feat}\")\n",
    "\n",
    "print(\"\\nDifferent features:\")\n",
    "for feat in different_features[:5]:  # Show first 5\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# Calculate distance\n",
    "distance = calculate_distance('p', 'f', method='hamming')\n",
    "print(f\"\\nHamming distance: {distance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Need for a Unified Framework\n",
    "\n",
    "Despite the importance of phonetic distance in historical linguistics, existing tools have limitations:\n",
    "\n",
    "### Current Approaches and Their Limitations\n",
    "\n",
    "1. **Ad-hoc Distance Matrices**: Many studies use manually crafted distance matrices based on linguistic intuition\n",
    "   - Not reproducible\n",
    "   - Not extensible to new sounds\n",
    "   - Difficult to validate\n",
    "\n",
    "2. **Simple Edit Distance**: Treats all substitutions equally\n",
    "   - [p] → [b] costs the same as [p] → [a]\n",
    "   - Ignores phonetic similarity\n",
    "\n",
    "3. **Sound Classes** (Dolgopolsky, ASJP): Groups similar sounds\n",
    "   - Coarse-grained (typically 10-40 classes)\n",
    "   - Loss of phonetic detail\n",
    "   - Arbitrary boundaries\n",
    "\n",
    "### Our Solution: distfeat\n",
    "\n",
    "distfeat provides a principled, reproducible approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfeat import build_distance_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Build distance matrix for stops\n",
    "stops = ['p', 'b', 't', 'd', 'k', 'g']\n",
    "matrix, labels = build_distance_matrix(stops, method='hamming')\n",
    "\n",
    "# Visualize the matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, \n",
    "            xticklabels=labels, \n",
    "            yticklabels=labels,\n",
    "            annot=True, \n",
    "            fmt='.3f',\n",
    "            cmap='YlOrRd',\n",
    "            vmin=0, vmax=1)\n",
    "plt.title('Phonetic Distance Matrix for Stops')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze the pattern\n",
    "print(\"Observations:\")\n",
    "print(f\"1. Voiced-voiceless pairs have small distances:\")\n",
    "for v, vl in [('p','b'), ('t','d'), ('k','g')]:\n",
    "    dist = calculate_distance(v, vl)\n",
    "    print(f\"   {v}-{vl}: {dist:.3f}\")\n",
    "\n",
    "print(f\"\\n2. Different places of articulation have larger distances:\")\n",
    "for v, vl in [('p','t'), ('p','k'), ('t','k')]:\n",
    "    dist = calculate_distance(v, vl)\n",
    "    print(f\"   {v}-{vl}: {dist:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Principles\n",
    "\n",
    "### 1. Feature-Based Representation\n",
    "\n",
    "Every phoneme is represented as a vector of binary features based on articulatory and acoustic properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfeat import get_feature_names\n",
    "\n",
    "# Get all feature names\n",
    "all_features = get_feature_names()\n",
    "print(f\"Total features: {len(all_features)}\")\n",
    "\n",
    "# Categorize features\n",
    "categories = {\n",
    "    'Major class': ['consonantal', 'sonorant', 'syllabic'],\n",
    "    'Manner': ['continuant', 'nasal', 'strident', 'lateral', 'delayedrelease'],\n",
    "    'Place': ['labial', 'coronal', 'dorsal', 'pharyngeal', 'glottal'],\n",
    "    'Voicing': ['voice', 'spreadglottis', 'constrictedglottis'],\n",
    "    'Secondary': ['round', 'anterior', 'distributed', 'high', 'low', 'back']\n",
    "}\n",
    "\n",
    "for category, features in categories.items():\n",
    "    available = [f for f in features if f in all_features]\n",
    "    print(f\"\\n{category} features: {', '.join(available)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multiple Distance Metrics\n",
    "\n",
    "Different linguistic questions require different distance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfeat import available_distance_methods\n",
    "\n",
    "# Compare different metrics\n",
    "methods = ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan']\n",
    "phoneme_pairs = [('p', 'b'), ('p', 'f'), ('p', 'k'), ('p', 'a')]\n",
    "\n",
    "print(\"Distance metrics comparison:\\n\")\n",
    "print(\"Pair    \", end=\"\")\n",
    "for method in methods:\n",
    "    print(f\"{method:>10}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for p1, p2 in phoneme_pairs:\n",
    "    print(f\"{p1}-{p2}     \", end=\"\")\n",
    "    for method in methods:\n",
    "        dist = calculate_distance(p1, p2, method=method)\n",
    "        if dist is not None:\n",
    "            print(f\"{dist:10.3f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"{'N/A':>10}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validation Against Cognate Data\n",
    "\n",
    "A key innovation is using cognate data to validate and optimize distance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distfeat.alignment import align_sequences\n",
    "\n",
    "# Example: Germanic cognates for \"water\"\n",
    "water_cognates = [\n",
    "    ['w', 'ɔː', 't', 'ər'],  # English water\n",
    "    ['v', 'a', 's', 'ər'],   # German Wasser\n",
    "    ['w', 'aː', 't', 'ər'],  # Dutch water\n",
    "]\n",
    "\n",
    "# Align first two cognates\n",
    "result = align_sequences(water_cognates[0], water_cognates[1])\n",
    "print(\"Alignment of English 'water' and German 'Wasser':\")\n",
    "print(f\"English: {' '.join(result.seq1_aligned)}\")\n",
    "print(f\"German:  {' '.join(result.seq2_aligned)}\")\n",
    "print(f\"Distance: {result.normalized_distance:.3f}\")\n",
    "\n",
    "# Compare with non-cognate\n",
    "non_cognate = ['m', 'a', 'ʁ']  # French \"mer\" (sea)\n",
    "result2 = align_sequences(water_cognates[0], non_cognate)\n",
    "print(f\"\\nDistance to non-cognate: {result2.normalized_distance:.3f}\")\n",
    "print(\"\\nCognates should have lower distances than non-cognates ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization of This Documentation\n",
    "\n",
    "This documentation is organized to serve both as a user guide and as the foundation for an academic paper:\n",
    "\n",
    "### Part I: Foundation\n",
    "- **Chapter 2**: Theoretical Foundation - The linguistic and mathematical basis\n",
    "- **Chapter 3**: Implementation Details - How distfeat works internally\n",
    "\n",
    "### Part II: Tutorials\n",
    "- **By Complexity**: Starting from single distances to full research applications\n",
    "- **By Use Case**: Practical scenarios from comparing words to analyzing sound changes\n",
    "\n",
    "### Part III: Validation & Benchmarks\n",
    "- **Chapter 4**: Experimental validation using cognate data\n",
    "- **Chapter 5**: Performance benchmarks and optimization\n",
    "- **Chapter 6**: Comparison with existing methods\n",
    "\n",
    "### Part IV: Case Studies\n",
    "Six detailed analyses across different language families:\n",
    "- Indo-European (Grimm's Law)\n",
    "- Austronesian (vowel harmony)\n",
    "- Sino-Tibetan (tone development)\n",
    "- Semitic (root patterns)\n",
    "- Bantu (noun classes)\n",
    "- Romance (lenition)\n",
    "\n",
    "### Part V: API Reference\n",
    "Complete documentation of all modules and functions\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **For practitioners**: Jump to the [Quick Start](../tutorials/00_quickstart.ipynb) tutorial\n",
    "- **For theorists**: Continue to [Chapter 2: Theoretical Foundation](02_theoretical_foundation.ipynb)\n",
    "- **For developers**: See the [API Reference](../api/features.ipynb)\n",
    "- **For researchers**: Explore the [Case Studies](../case_studies/indo_european.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}