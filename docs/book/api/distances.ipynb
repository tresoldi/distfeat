{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances Module API Reference\n",
    "\n",
    "The `distfeat.distances` module provides comprehensive phonetic distance calculation functionality. This module handles:\n",
    "\n",
    "- Calculating distances between individual phonemes\n",
    "- Building distance matrices for phoneme sets\n",
    "- Multiple distance metrics (Hamming, Jaccard, Euclidean, Cosine, Manhattan, K-means)\n",
    "- Custom distance method registration\n",
    "- Performance optimization with caching\n",
    "- Matrix-based operations for large-scale analysis\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```python\n",
    "from distfeat import calculate_distance, build_distance_matrix, available_distance_methods\n",
    "\n",
    "# Calculate distance between two phonemes\n",
    "distance = calculate_distance('p', 'b', method='hamming')\n",
    "print(f\"Distance p-b: {distance:.3f}\")\n",
    "\n",
    "# Build distance matrix for a set of phonemes\n",
    "matrix, phonemes = build_distance_matrix(['p', 'b', 't', 'd'], method='euclidean')\n",
    "print(f\"Matrix shape: {matrix.shape}\")\n",
    "\n",
    "# List available methods\n",
    "methods = available_distance_methods()\n",
    "print(f\"Available methods: {methods}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "\n",
    "### calculate_distance()\n",
    "\n",
    "Calculate the phonetic distance between two phonemes using various metrics.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "calculate_distance(\n",
    "    phoneme1: str,\n",
    "    phoneme2: str,\n",
    "    method: str = 'hamming',\n",
    "    normalize: bool = True,\n",
    "    on_error: str = 'warn',\n",
    "    **kwargs\n",
    ") -> Optional[float]\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `phoneme1` (str): First IPA phoneme symbol\n",
    "- `phoneme2` (str): Second IPA phoneme symbol\n",
    "- `method` (str): Distance calculation method - 'hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan', 'kmeans'\n",
    "- `normalize` (bool): Normalize distance to [0, 1] range (default: True)\n",
    "- `on_error` (str): Error handling mode - 'raise', 'warn', or 'ignore'\n",
    "- `**kwargs`: Additional arguments for specific methods (e.g., n_clusters for k-means)\n",
    "\n",
    "**Returns:**\n",
    "- `float` or `None`: Distance value in [0, 1] range (if normalized), or None if phonemes not found\n",
    "\n",
    "**Caching:**\n",
    "Function uses `@lru_cache(maxsize=4096)` for performance optimization.\n",
    "\n",
    "**Distance Methods:**\n",
    "- **Hamming**: Count of differing binary features\n",
    "- **Jaccard**: 1 - (intersection / union) of positive features\n",
    "- **Euclidean**: L2 norm of feature vector difference\n",
    "- **Cosine**: 1 - cosine similarity of feature vectors\n",
    "- **Manhattan**: L1 norm (sum of absolute differences)\n",
    "- **K-means**: Distance based on cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of calculate_distance()\n",
    "import sys\n",
    "sys.path.append('/home/tiagot/tiatre/unipa/distfeat')\n",
    "from distfeat import calculate_distance\n",
    "\n",
    "# Compare all distance methods for p vs b (voicing difference)\n",
    "phoneme_pair = ('p', 'b')\n",
    "methods = ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan']\n",
    "\n",
    "print(f\"Distance between /{phoneme_pair[0]}/ and /{phoneme_pair[1]}/ (voicing difference):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "distances = {}\n",
    "for method in methods:\n",
    "    dist = calculate_distance(phoneme_pair[0], phoneme_pair[1], method=method)\n",
    "    distances[method] = dist\n",
    "    print(f\"{method:<12}: {dist:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Compare different phoneme pairs with Hamming distance\n",
    "pairs = [('p', 'b'), ('p', 't'), ('p', 'k'), ('a', 'i'), ('s', 'ʃ')]\n",
    "print(\"Hamming distances for various phoneme pairs:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for p1, p2 in pairs:\n",
    "    dist = calculate_distance(p1, p2, method='hamming')\n",
    "    if dist is not None:\n",
    "        print(f\"/{p1}/ - /{p2}/: {dist:.3f}\")\n",
    "    else:\n",
    "        print(f\"/{p1}/ - /{p2}/: phoneme not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced distance method examples\n",
    "\n",
    "# K-means clustering distance with different cluster numbers\n",
    "print(\"K-means distance with different cluster numbers:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for n_clusters in [5, 10, 15, 20]:\n",
    "    dist = calculate_distance('p', 't', method='kmeans', n_clusters=n_clusters)\n",
    "    if dist is not None:\n",
    "        print(f\"n_clusters={n_clusters:2d}: {dist:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Normalization effects\n",
    "phoneme_pair = ('p', 'a')  # Very different phonemes\n",
    "methods = ['hamming', 'euclidean', 'manhattan']\n",
    "\n",
    "print(f\"Normalization effects for /{phoneme_pair[0]}/ vs /{phoneme_pair[1]}/:\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Method':<12} {'Normalized':<12} {'Raw':<12}\")\n",
    "\n",
    "for method in methods:\n",
    "    normalized = calculate_distance(phoneme_pair[0], phoneme_pair[1], \n",
    "                                  method=method, normalize=True)\n",
    "    raw = calculate_distance(phoneme_pair[0], phoneme_pair[1], \n",
    "                           method=method, normalize=False)\n",
    "    \n",
    "    if normalized is not None and raw is not None:\n",
    "        print(f\"{method:<12} {normalized:<12.4f} {raw:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build_distance_matrix()\n",
    "\n",
    "Build a symmetric distance matrix for a set of phonemes.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "build_distance_matrix(\n",
    "    phonemes: Optional[List[str]] = None,\n",
    "    method: str = 'hamming',\n",
    "    normalize: bool = True,\n",
    "    n_clusters: Optional[int] = None,\n",
    "    cache: bool = True\n",
    ") -> Tuple[np.ndarray, List[str]]\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `phonemes` (Optional[List[str]]): List of phonemes to include (None for all phonemes in system)\n",
    "- `method` (str): Distance method to use\n",
    "- `normalize` (bool): Normalize distances to [0, 1] range\n",
    "- `n_clusters` (Optional[int]): Number of clusters for k-means method\n",
    "- `cache` (bool): Use cached distance calculations for better performance\n",
    "\n",
    "**Returns:**\n",
    "- `Tuple[np.ndarray, List[str]]`: (distance_matrix, phoneme_list)\n",
    "  - `distance_matrix`: Square symmetric matrix of shape (n_phonemes, n_phonemes)\n",
    "  - `phoneme_list`: Ordered list of phonemes corresponding to matrix rows/columns\n",
    "\n",
    "**Properties:**\n",
    "- Matrix is symmetric: `matrix[i,j] = matrix[j,i]`\n",
    "- Diagonal is zero: `matrix[i,i] = 0`\n",
    "- Missing phonemes get maximum distance (1.0 if normalized, inf otherwise)\n",
    "- For large phoneme sets, caching provides significant speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of build_distance_matrix()\n",
    "from distfeat import build_distance_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Small matrix for consonant stops\n",
    "stops = ['p', 'b', 't', 'd', 'k', 'g']\n",
    "matrix, phoneme_list = build_distance_matrix(stops, method='hamming')\n",
    "\n",
    "print(\"Distance matrix for stops (Hamming):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Shape: {matrix.shape}\")\n",
    "print(f\"Phonemes: {phoneme_list}\")\n",
    "\n",
    "# Display matrix with phoneme labels\n",
    "print(\"\\nMatrix values:\")\n",
    "print(f\"{'':>4}\", end=\"\")\n",
    "for p in phoneme_list:\n",
    "    print(f\"{p:>6}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, p1 in enumerate(phoneme_list):\n",
    "    print(f\"{p1:>4}\", end=\"\")\n",
    "    for j, p2 in enumerate(phoneme_list):\n",
    "        print(f\"{matrix[i,j]:>6.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Matrix properties verification\n",
    "print(\"Matrix properties:\")\n",
    "print(f\"  Symmetric: {np.allclose(matrix, matrix.T)}\")\n",
    "print(f\"  Zero diagonal: {np.allclose(np.diag(matrix), 0)}\")\n",
    "print(f\"  Min value: {np.min(matrix):.4f}\")\n",
    "print(f\"  Max value: {np.max(matrix):.4f}\")\n",
    "print(f\"  Mean distance: {np.mean(matrix[np.triu_indices_from(matrix, k=1)]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing different distance methods on same phoneme set\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "methods = ['hamming', 'jaccard', 'euclidean', 'cosine']\n",
    "\n",
    "print(\"Vowel distance matrices by method:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method in methods:\n",
    "    matrix, phonemes = build_distance_matrix(vowels, method=method)\n",
    "    \n",
    "    print(f\"\\n{method.upper()} distances:\")\n",
    "    print(f\"{'':>4}\", end=\"\")\n",
    "    for p in phonemes:\n",
    "        print(f\"{p:>6}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i, p1 in enumerate(phonemes):\n",
    "        print(f\"{p1:>4}\", end=\"\")\n",
    "        for j, p2 in enumerate(phonemes):\n",
    "            print(f\"{matrix[i,j]:>6.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    upper_tri = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    print(f\"    Mean: {np.mean(upper_tri):.3f}, Std: {np.std(upper_tri):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison: cached vs uncached\n",
    "import time\n",
    "\n",
    "test_phonemes = ['p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'ŋ', 'f', 'v', 's', 'z']\n",
    "\n",
    "print(\"Performance comparison (cached vs uncached):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Cached version\n",
    "start = time.time()\n",
    "matrix_cached, _ = build_distance_matrix(test_phonemes, method='hamming', cache=True)\n",
    "cached_time = time.time() - start\n",
    "\n",
    "# Uncached version\n",
    "start = time.time()\n",
    "matrix_uncached, _ = build_distance_matrix(test_phonemes, method='hamming', cache=False)\n",
    "uncached_time = time.time() - start\n",
    "\n",
    "print(f\"Cached time:   {cached_time:.6f} seconds\")\n",
    "print(f\"Uncached time: {uncached_time:.6f} seconds\")\n",
    "print(f\"Speedup:       {uncached_time / cached_time:.1f}x\")\n",
    "print(f\"Results match: {np.allclose(matrix_cached, matrix_uncached)}\")\n",
    "\n",
    "print(f\"\\nMatrix size: {len(test_phonemes)} phonemes = {len(test_phonemes)**2} distances\")\n",
    "print(f\"Unique distances: {len(test_phonemes) * (len(test_phonemes) - 1) // 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### available_distance_methods()\n",
    "\n",
    "Get a list of all available distance calculation methods.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "available_distance_methods() -> List[str]\n",
    "```\n",
    "\n",
    "**Returns:**\n",
    "- `List[str]`: List of method names (built-in + custom registered methods)\n",
    "\n",
    "**Built-in Methods:**\n",
    "- `'hamming'`: Binary feature difference count\n",
    "- `'jaccard'`: Set-based similarity measure\n",
    "- `'euclidean'`: L2 geometric distance\n",
    "- `'cosine'`: Angular similarity measure\n",
    "- `'manhattan'`: L1 city-block distance\n",
    "- `'kmeans'`: Cluster-based distance\n",
    "\n",
    "**Custom Methods:**\n",
    "Methods registered via `register_distance_method()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of available_distance_methods()\n",
    "from distfeat import available_distance_methods\n",
    "\n",
    "# List all available methods\n",
    "methods = available_distance_methods()\n",
    "print(f\"Available distance methods ({len(methods)} total):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, method in enumerate(methods, 1):\n",
    "    print(f\"{i:2d}. {method}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Method characteristics\n",
    "method_info = {\n",
    "    'hamming': 'Binary difference count (good for categorical features)',\n",
    "    'jaccard': 'Set similarity (emphasizes shared positive features)',\n",
    "    'euclidean': 'Geometric distance (sensitive to feature magnitude)',\n",
    "    'cosine': 'Angular similarity (normalized by vector length)',\n",
    "    'manhattan': 'City-block distance (robust to outliers)',\n",
    "    'kmeans': 'Cluster-based distance (data-driven grouping)'\n",
    "}\n",
    "\n",
    "print(\"Method characteristics:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for method in methods:\n",
    "    if method in method_info:\n",
    "        print(f\"{method:<10}: {method_info[method]}\")\n",
    "    else:\n",
    "        print(f\"{method:<10}: Custom registered method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register_distance_method()\n",
    "\n",
    "Register a custom distance calculation method.\n",
    "\n",
    "**Signature:**\n",
    "```python\n",
    "register_distance_method(name: str, func: Callable) -> None\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `name` (str): Name for the distance method (used in `calculate_distance()`)\n",
    "- `func` (Callable): Function that takes two numpy arrays and returns a float distance\n",
    "\n",
    "**Function Requirements:**\n",
    "```python\n",
    "def custom_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    # vec1, vec2 are binary feature vectors (0s and 1s)\n",
    "    # Return non-negative distance value\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "- Custom functions receive normalized binary feature vectors\n",
    "- Normalization (if requested) is handled automatically\n",
    "- Function should return non-negative values\n",
    "- Name must not conflict with built-in methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of register_distance_method()\n",
    "from distfeat import register_distance_method, calculate_distance\n",
    "import numpy as np\n",
    "\n",
    "# Define custom distance methods\n",
    "\n",
    "def dice_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Dice coefficient distance (similar to Jaccard but different formula).\"\"\"\n",
    "    intersection = np.sum((vec1 == 1) & (vec2 == 1))\n",
    "    total_positive = np.sum(vec1) + np.sum(vec2)\n",
    "    \n",
    "    if total_positive == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dice_coeff = (2 * intersection) / total_positive\n",
    "    return 1.0 - dice_coeff\n",
    "\n",
    "def weighted_hamming(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Weighted Hamming distance (early features matter more).\"\"\"\n",
    "    differences = (vec1 != vec2).astype(float)\n",
    "    # Give higher weights to earlier features\n",
    "    weights = np.exp(-np.arange(len(vec1)) / 10)\n",
    "    return np.sum(differences * weights) / np.sum(weights)\n",
    "\n",
    "def overlap_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Simple overlap distance (fraction of non-matching features).\"\"\"\n",
    "    if len(vec1) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(vec1 != vec2)\n",
    "\n",
    "# Register the custom methods\n",
    "print(\"Registering custom distance methods:\")\n",
    "register_distance_method('dice', dice_distance)\n",
    "register_distance_method('weighted_hamming', weighted_hamming)\n",
    "register_distance_method('overlap', overlap_distance)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test custom methods\n",
    "test_pairs = [('p', 'b'), ('p', 't'), ('a', 'i')]\n",
    "custom_methods = ['dice', 'weighted_hamming', 'overlap']\n",
    "\n",
    "print(\"Testing custom distance methods:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Pair':<8} {'Dice':<8} {'W.Ham':<8} {'Overlap':<8}\")\n",
    "\n",
    "for p1, p2 in test_pairs:\n",
    "    results = []\n",
    "    for method in custom_methods:\n",
    "        dist = calculate_distance(p1, p2, method=method)\n",
    "        results.append(f\"{dist:.3f}\" if dist is not None else \"N/A\")\n",
    "    \n",
    "    print(f\"{p1}-{p2:<5} {results[0]:<8} {results[1]:<8} {results[2]:<8}\")\n",
    "\n",
    "# Verify methods are available\n",
    "print(\"\\nUpdated available methods:\")\n",
    "updated_methods = available_distance_methods()\n",
    "custom_count = len(updated_methods) - 6  # 6 built-in methods\n",
    "print(f\"Total methods: {len(updated_methods)} ({custom_count} custom)\")\n",
    "print(f\"Custom methods: {[m for m in updated_methods if m not in ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan', 'kmeans']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "### Phonetic Distance Analysis\n",
    "\n",
    "Analyze phonetic relationships using distance matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced: Phonetic distance analysis\n",
    "import numpy as np\n",
    "from distfeat import build_distance_matrix\n",
    "\n",
    "def analyze_phonetic_groups(phonemes, group_labels, method='hamming'):\n",
    "    \"\"\"Analyze within-group vs between-group distances.\"\"\"\n",
    "    matrix, phoneme_list = build_distance_matrix(phonemes, method=method)\n",
    "    \n",
    "    # Create group mapping\n",
    "    phoneme_to_group = dict(zip(phonemes, group_labels))\n",
    "    \n",
    "    within_group = []\n",
    "    between_group = []\n",
    "    \n",
    "    for i, p1 in enumerate(phoneme_list):\n",
    "        for j, p2 in enumerate(phoneme_list):\n",
    "            if i < j:  # Upper triangle only\n",
    "                distance = matrix[i, j]\n",
    "                if phoneme_to_group[p1] == phoneme_to_group[p2]:\n",
    "                    within_group.append(distance)\n",
    "                else:\n",
    "                    between_group.append(distance)\n",
    "    \n",
    "    return {\n",
    "        'within_mean': np.mean(within_group),\n",
    "        'within_std': np.std(within_group),\n",
    "        'between_mean': np.mean(between_group),\n",
    "        'between_std': np.std(between_group),\n",
    "        'separation_ratio': np.mean(between_group) / np.mean(within_group),\n",
    "        'within_distances': within_group,\n",
    "        'between_distances': between_group\n",
    "    }\n",
    "\n",
    "# Test with stop consonants grouped by voicing\n",
    "stops = ['p', 'b', 't', 'd', 'k', 'g']\n",
    "voicing = ['voiceless', 'voiced', 'voiceless', 'voiced', 'voiceless', 'voiced']\n",
    "\n",
    "analysis = analyze_phonetic_groups(stops, voicing, method='hamming')\n",
    "\n",
    "print(\"Voicing-based grouping analysis (stops):\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Within-group (same voicing):\")\n",
    "print(f\"  Mean distance: {analysis['within_mean']:.4f}\")\n",
    "print(f\"  Std deviation: {analysis['within_std']:.4f}\")\n",
    "print(f\"\\nBetween-group (different voicing):\")\n",
    "print(f\"  Mean distance: {analysis['between_mean']:.4f}\")\n",
    "print(f\"  Std deviation: {analysis['between_std']:.4f}\")\n",
    "print(f\"\\nSeparation ratio: {analysis['separation_ratio']:.2f}\")\n",
    "print(f\"(Higher ratio = better group separation)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test with place of articulation grouping\n",
    "place_groups = ['labial', 'labial', 'coronal', 'coronal', 'dorsal', 'dorsal']\n",
    "place_analysis = analyze_phonetic_groups(stops, place_groups, method='hamming')\n",
    "\n",
    "print(\"Place-based grouping analysis (stops):\")\n",
    "print(\"=\" * 42)\n",
    "print(f\"Within-group: {place_analysis['within_mean']:.4f} ± {place_analysis['within_std']:.4f}\")\n",
    "print(f\"Between-group: {place_analysis['between_mean']:.4f} ± {place_analysis['between_std']:.4f}\")\n",
    "print(f\"Separation ratio: {place_analysis['separation_ratio']:.2f}\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Voicing separation: {analysis['separation_ratio']:.2f}\")\n",
    "print(f\"Place separation:   {place_analysis['separation_ratio']:.2f}\")\n",
    "better = \"Voicing\" if analysis['separation_ratio'] > place_analysis['separation_ratio'] else \"Place\"\n",
    "print(f\"Better grouping principle: {better}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix Visualization and Analysis\n",
    "\n",
    "Tools for analyzing and visualizing distance matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced: Distance matrix analysis\n",
    "import numpy as np\n",
    "from distfeat import build_distance_matrix\n",
    "\n",
    "def matrix_statistics(matrix, phonemes):\n",
    "    \"\"\"Calculate comprehensive statistics for a distance matrix.\"\"\"\n",
    "    # Get upper triangle (unique distances)\n",
    "    upper_tri = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    \n",
    "    # Basic statistics\n",
    "    stats = {\n",
    "        'size': matrix.shape[0],\n",
    "        'total_distances': len(upper_tri),\n",
    "        'min_distance': np.min(upper_tri),\n",
    "        'max_distance': np.max(upper_tri),\n",
    "        'mean_distance': np.mean(upper_tri),\n",
    "        'median_distance': np.median(upper_tri),\n",
    "        'std_distance': np.std(upper_tri),\n",
    "    }\n",
    "    \n",
    "    # Find most similar and dissimilar pairs\n",
    "    min_idx = np.unravel_index(np.argmin(matrix + np.eye(len(matrix))), matrix.shape)\n",
    "    max_idx = np.unravel_index(np.argmax(matrix), matrix.shape)\n",
    "    \n",
    "    stats['most_similar'] = (phonemes[min_idx[0]], phonemes[min_idx[1]], matrix[min_idx])\n",
    "    stats['most_dissimilar'] = (phonemes[max_idx[0]], phonemes[max_idx[1]], matrix[max_idx])\n",
    "    \n",
    "    # Distance distribution\n",
    "    hist, bins = np.histogram(upper_tri, bins=10)\n",
    "    stats['distribution'] = list(zip(bins[:-1], bins[1:], hist))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def compare_distance_methods(phonemes, methods=['hamming', 'jaccard', 'euclidean']):\n",
    "    \"\"\"Compare different distance methods on the same phoneme set.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        matrix, phoneme_list = build_distance_matrix(phonemes, method=method)\n",
    "        stats = matrix_statistics(matrix, phoneme_list)\n",
    "        results[method] = stats\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with consonants\n",
    "consonants = ['p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'ŋ', 'f', 'v', 's', 'z']\n",
    "comparison = compare_distance_methods(consonants)\n",
    "\n",
    "print(\"Distance method comparison (consonants):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Method':<12} {'Mean':<8} {'Std':<8} {'Min':<8} {'Max':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for method, stats in comparison.items():\n",
    "    print(f\"{method:<12} {stats['mean_distance']:<8.3f} {stats['std_distance']:<8.3f} \"\n",
    "          f\"{stats['min_distance']:<8.3f} {stats['max_distance']:<8.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Most similar/dissimilar pairs by method\n",
    "print(\"Most similar and dissimilar pairs:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for method, stats in comparison.items():\n",
    "    similar = stats['most_similar']\n",
    "    dissimilar = stats['most_dissimilar']\n",
    "    \n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    print(f\"  Most similar:    {similar[0]}-{similar[1]} ({similar[2]:.3f})\")\n",
    "    print(f\"  Most dissimilar: {dissimilar[0]}-{dissimilar[1]} ({dissimilar[2]:.3f})\")\n",
    "\n",
    "# Matrix correlations\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"Method correlations:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "methods = list(comparison.keys())\n",
    "matrices = {}\n",
    "for method in methods:\n",
    "    matrix, _ = build_distance_matrix(consonants, method=method)\n",
    "    matrices[method] = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "\n",
    "for i, method1 in enumerate(methods):\n",
    "    for method2 in methods[i+1:]:\n",
    "        correlation = np.corrcoef(matrices[method1], matrices[method2])[0, 1]\n",
    "        print(f\"{method1} - {method2}: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Optimization\n",
    "\n",
    "Techniques for optimizing distance calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimization examples\n",
    "import time\n",
    "from distfeat import calculate_distance, build_distance_matrix\n",
    "\n",
    "def benchmark_methods(phonemes, methods=['hamming', 'euclidean', 'cosine'], iterations=3):\n",
    "    \"\"\"Benchmark different distance methods.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        times = []\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            start = time.time()\n",
    "            build_distance_matrix(phonemes, method=method)\n",
    "            times.append(time.time() - start)\n",
    "        \n",
    "        results[method] = {\n",
    "            'mean_time': np.mean(times),\n",
    "            'std_time': np.std(times),\n",
    "            'min_time': np.min(times),\n",
    "            'max_time': np.max(times)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def cache_performance_test():\n",
    "    \"\"\"Test LRU cache performance.\"\"\"\n",
    "    # Clear cache\n",
    "    calculate_distance.cache_clear()\n",
    "    \n",
    "    test_pairs = [('p', 'b'), ('t', 'd'), ('k', 'g')] * 100\n",
    "    \n",
    "    # First run (cache misses)\n",
    "    start = time.time()\n",
    "    for p1, p2 in test_pairs:\n",
    "        calculate_distance(p1, p2)\n",
    "    first_run = time.time() - start\n",
    "    \n",
    "    # Second run (cache hits)\n",
    "    start = time.time()\n",
    "    for p1, p2 in test_pairs:\n",
    "        calculate_distance(p1, p2)\n",
    "    second_run = time.time() - start\n",
    "    \n",
    "    cache_info = calculate_distance.cache_info()\n",
    "    \n",
    "    return {\n",
    "        'first_run': first_run,\n",
    "        'second_run': second_run,\n",
    "        'speedup': first_run / second_run,\n",
    "        'cache_info': cache_info\n",
    "    }\n",
    "\n",
    "# Benchmark different methods\n",
    "test_phonemes = ['p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'f', 'v']\n",
    "bench_results = benchmark_methods(test_phonemes)\n",
    "\n",
    "print(f\"Performance benchmark ({len(test_phonemes)} phonemes):\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Method':<12} {'Mean (ms)':<12} {'Std (ms)':<12} {'Min (ms)':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for method, stats in bench_results.items():\n",
    "    print(f\"{method:<12} {stats['mean_time']*1000:<12.2f} \"\n",
    "          f\"{stats['std_time']*1000:<12.2f} {stats['min_time']*1000:<12.2f}\")\n",
    "\n",
    "# Find fastest method\n",
    "fastest = min(bench_results.items(), key=lambda x: x[1]['mean_time'])\n",
    "print(f\"\\nFastest method: {fastest[0]} ({fastest[1]['mean_time']*1000:.2f} ms)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Cache performance\n",
    "cache_results = cache_performance_test()\n",
    "\n",
    "print(\"Cache performance test:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"First run (cache misses):  {cache_results['first_run']*1000:.2f} ms\")\n",
    "print(f\"Second run (cache hits):   {cache_results['second_run']*1000:.2f} ms\")\n",
    "print(f\"Cache speedup:             {cache_results['speedup']:.1f}x\")\n",
    "print(f\"\\nCache statistics:\")\n",
    "info = cache_results['cache_info']\n",
    "print(f\"  Hits: {info.hits}, Misses: {info.misses}\")\n",
    "print(f\"  Hit rate: {info.hits / (info.hits + info.misses) * 100:.1f}%\")\n",
    "print(f\"  Cache size: {info.currsize}/{info.maxsize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Method Details\n",
    "\n",
    "### Mathematical Formulations\n",
    "\n",
    "Each distance method implements a specific mathematical formula:\n",
    "\n",
    "**Hamming Distance:**\n",
    "```\n",
    "hamming(x, y) = Σᵢ (xᵢ ≠ yᵢ) / n\n",
    "```\n",
    "Counts the fraction of positions where binary features differ.\n",
    "\n",
    "**Jaccard Distance:**\n",
    "```\n",
    "jaccard(x, y) = 1 - |A ∩ B| / |A ∪ B|\n",
    "```\n",
    "Where A and B are sets of positive features in x and y.\n",
    "\n",
    "**Euclidean Distance:**\n",
    "```\n",
    "euclidean(x, y) = √(Σᵢ (xᵢ - yᵢ)²) / √n\n",
    "```\n",
    "L2 norm normalized by dimension.\n",
    "\n",
    "**Cosine Distance:**\n",
    "```\n",
    "cosine(x, y) = 1 - (x·y) / (||x|| ||y||)\n",
    "```\n",
    "Angular distance between feature vectors.\n",
    "\n",
    "**Manhattan Distance:**\n",
    "```\n",
    "manhattan(x, y) = Σᵢ |xᵢ - yᵢ| / n\n",
    "```\n",
    "L1 norm normalized by dimension.\n",
    "\n",
    "**K-means Distance:**\n",
    "```\n",
    "kmeans(x, y) = ||c(x) - c(y)|| / max_dist\n",
    "```\n",
    "Where c(x) is the centroid of the cluster containing phoneme x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical verification of distance methods\n",
    "from distfeat import calculate_distance, phoneme_to_features, get_feature_names\n",
    "import numpy as np\n",
    "\n",
    "def manual_hamming(p1, p2):\n",
    "    \"\"\"Manual Hamming distance calculation for verification.\"\"\"\n",
    "    f1 = phoneme_to_features(p1)\n",
    "    f2 = phoneme_to_features(p2)\n",
    "    if f1 is None or f2 is None:\n",
    "        return None\n",
    "    \n",
    "    feature_names = get_feature_names()\n",
    "    differences = sum(1 for f in feature_names if f1.get(f, 0) != f2.get(f, 0))\n",
    "    return differences / len(feature_names)\n",
    "\n",
    "def manual_jaccard(p1, p2):\n",
    "    \"\"\"Manual Jaccard distance calculation for verification.\"\"\"\n",
    "    f1 = phoneme_to_features(p1)\n",
    "    f2 = phoneme_to_features(p2)\n",
    "    if f1 is None or f2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Get positive features\n",
    "    pos1 = set(f for f, v in f1.items() if v == 1)\n",
    "    pos2 = set(f for f, v in f2.items() if v == 1)\n",
    "    \n",
    "    intersection = len(pos1 & pos2)\n",
    "    union = len(pos1 | pos2)\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return 1.0 - (intersection / union)\n",
    "\n",
    "# Verification tests\n",
    "test_pairs = [('p', 'b'), ('p', 't'), ('a', 'i')]\n",
    "\n",
    "print(\"Mathematical verification:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Pair':<6} {'Method':<8} {'Library':<8} {'Manual':<8} {'Match':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for p1, p2 in test_pairs:\n",
    "    # Hamming\n",
    "    lib_hamming = calculate_distance(p1, p2, method='hamming')\n",
    "    man_hamming = manual_hamming(p1, p2)\n",
    "    \n",
    "    if lib_hamming is not None and man_hamming is not None:\n",
    "        hamming_match = abs(lib_hamming - man_hamming) < 1e-6\n",
    "        print(f\"{p1}-{p2:<3} {'hamming':<8} {lib_hamming:<8.4f} {man_hamming:<8.4f} {hamming_match!s:<8}\")\n",
    "    \n",
    "    # Jaccard\n",
    "    lib_jaccard = calculate_distance(p1, p2, method='jaccard')\n",
    "    man_jaccard = manual_jaccard(p1, p2)\n",
    "    \n",
    "    if lib_jaccard is not None and man_jaccard is not None:\n",
    "        jaccard_match = abs(lib_jaccard - man_jaccard) < 1e-6\n",
    "        print(f\"{' ':<6} {'jaccard':<8} {lib_jaccard:<8.4f} {man_jaccard:<8.4f} {jaccard_match!s:<8}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Distance properties verification\n",
    "print(\"Distance metric properties:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "methods = ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan']\n",
    "test_phonemes = ['p', 'b', 't']\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    \n",
    "    # Identity: d(x,x) = 0\n",
    "    identity = all(calculate_distance(p, p, method=method) == 0.0 for p in test_phonemes)\n",
    "    print(f\"  Identity: {identity}\")\n",
    "    \n",
    "    # Symmetry: d(x,y) = d(y,x)\n",
    "    symmetry = all(\n",
    "        abs(calculate_distance(p1, p2, method=method) - \n",
    "            calculate_distance(p2, p1, method=method)) < 1e-6\n",
    "        for p1 in test_phonemes for p2 in test_phonemes\n",
    "    )\n",
    "    print(f\"  Symmetry: {symmetry}\")\n",
    "    \n",
    "    # Non-negativity: d(x,y) >= 0\n",
    "    non_negative = all(\n",
    "        calculate_distance(p1, p2, method=method) >= 0\n",
    "        for p1 in test_phonemes for p2 in test_phonemes\n",
    "    )\n",
    "    print(f\"  Non-negative: {non_negative}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Edge Cases\n",
    "\n",
    "The distances module provides robust error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling examples\n",
    "from distfeat import calculate_distance, build_distance_matrix\n",
    "import warnings\n",
    "\n",
    "print(\"Error handling scenarios:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Unknown phonemes\n",
    "print(\"\\n1. Unknown phonemes:\")\n",
    "for error_mode in ['warn', 'ignore', 'raise']:\n",
    "    try:\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\")\n",
    "            result = calculate_distance('p', 'xyz', on_error=error_mode)\n",
    "            warn_count = len(w)\n",
    "        print(f\"   {error_mode:<6}: result={result}, warnings={warn_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   {error_mode:<6}: {type(e).__name__} - {str(e)[:40]}...\")\n",
    "\n",
    "# 2. Unknown distance method\n",
    "print(\"\\n2. Unknown distance method:\")\n",
    "try:\n",
    "    calculate_distance('p', 'b', method='nonexistent')\n",
    "except ValueError as e:\n",
    "    print(f\"   ValueError: {e}\")\n",
    "\n",
    "# 3. Empty phoneme list\n",
    "print(\"\\n3. Empty phoneme list:\")\n",
    "matrix, phonemes = build_distance_matrix([])\n",
    "print(f\"   Matrix shape: {matrix.shape}\")\n",
    "print(f\"   Phoneme list: {phonemes}\")\n",
    "\n",
    "# 4. Single phoneme\n",
    "print(\"\\n4. Single phoneme:\")\n",
    "matrix, phonemes = build_distance_matrix(['p'])\n",
    "print(f\"   Matrix shape: {matrix.shape}\")\n",
    "print(f\"   Matrix content: {matrix[0,0]}\")\n",
    "\n",
    "# 5. Mixed valid/invalid phonemes\n",
    "print(\"\\n5. Mixed valid/invalid phonemes:\")\n",
    "mixed_phonemes = ['p', 'xyz', 'b', 'abc']\n",
    "matrix, valid_phonemes = build_distance_matrix(mixed_phonemes)\n",
    "print(f\"   Input: {mixed_phonemes}\")\n",
    "print(f\"   Output phonemes: {valid_phonemes}\")\n",
    "print(f\"   Matrix shape: {matrix.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Edge cases for specific distance methods\n",
    "print(\"Distance method edge cases:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Zero vectors (if they exist)\n",
    "print(\"\\n1. Identical phonemes (should be 0.0):\")\n",
    "for method in ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan']:\n",
    "    dist = calculate_distance('p', 'p', method=method)\n",
    "    print(f\"   {method:<10}: {dist}\")\n",
    "\n",
    "# Very different phonemes\n",
    "print(\"\\n2. Very different phonemes (consonant vs vowel):\")\n",
    "for method in ['hamming', 'jaccard', 'euclidean', 'cosine', 'manhattan']:\n",
    "    dist = calculate_distance('p', 'a', method=method)\n",
    "    if dist is not None:\n",
    "        print(f\"   {method:<10}: {dist:.4f}\")\n",
    "\n",
    "# Performance with large matrices\n",
    "print(\"\\n3. Large matrix handling:\")\n",
    "import time\n",
    "\n",
    "# Test with 20 phonemes (190 unique distances)\n",
    "large_set = ['p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'ŋ', 'f', \n",
    "             'v', 's', 'z', 'ʃ', 'ʒ', 'x', 'ɣ', 'h', 'l', 'r']\n",
    "\n",
    "start = time.time()\n",
    "matrix, phonemes = build_distance_matrix(large_set, method='hamming')\n",
    "elapsed = time.time() - start\n",
    "\n",
    "unique_distances = len(large_set) * (len(large_set) - 1) // 2\n",
    "print(f\"   {len(large_set)} phonemes = {unique_distances} unique distances\")\n",
    "print(f\"   Computation time: {elapsed:.4f} seconds\")\n",
    "print(f\"   Rate: {unique_distances/elapsed:.0f} distances/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Examples\n",
    "\n",
    "### Working with Features Module\n",
    "\n",
    "The distances module integrates seamlessly with the features system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with features module\n",
    "from distfeat import phoneme_to_features, calculate_distance, build_distance_matrix\n",
    "import numpy as np\n",
    "\n",
    "def feature_based_clustering(phonemes, n_clusters=3, method='hamming'):\n",
    "    \"\"\"Cluster phonemes based on distances.\"\"\"\n",
    "    matrix, phoneme_list = build_distance_matrix(phonemes, method=method)\n",
    "    \n",
    "    # Simple hierarchical clustering based on distances\n",
    "    clusters = {i: [phoneme] for i, phoneme in enumerate(phoneme_list)}\n",
    "    distances = matrix.copy()\n",
    "    np.fill_diagonal(distances, np.inf)  # Ignore self-distances\n",
    "    \n",
    "    while len(clusters) > n_clusters:\n",
    "        # Find closest pair\n",
    "        min_idx = np.unravel_index(np.argmin(distances), distances.shape)\n",
    "        i, j = min_idx\n",
    "        \n",
    "        # Merge clusters\n",
    "        if i in clusters and j in clusters:\n",
    "            clusters[i].extend(clusters[j])\n",
    "            del clusters[j]\n",
    "            \n",
    "            # Update distances (set merged phonemes to infinite distance)\n",
    "            distances[j, :] = np.inf\n",
    "            distances[:, j] = np.inf\n",
    "    \n",
    "    return list(clusters.values())\n",
    "\n",
    "# Test clustering\n",
    "test_consonants = ['p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'ŋ']\n",
    "clusters = feature_based_clustering(test_consonants, n_clusters=3)\n",
    "\n",
    "print(\"Phoneme clustering based on Hamming distances:\")\n",
    "print(\"=\" * 50)\n",
    "for i, cluster in enumerate(clusters, 1):\n",
    "    print(f\"Cluster {i}: {cluster}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Feature analysis of clusters\n",
    "print(\"Feature analysis of clusters:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for i, cluster in enumerate(clusters, 1):\n",
    "    print(f\"\\nCluster {i} ({', '.join(cluster)}):\")\n",
    "    \n",
    "    # Get features for all phonemes in cluster\n",
    "    all_features = [phoneme_to_features(p) for p in cluster]\n",
    "    all_features = [f for f in all_features if f is not None]\n",
    "    \n",
    "    if all_features:\n",
    "        # Find shared features (present in all phonemes)\n",
    "        shared_features = set(all_features[0].keys())\n",
    "        for features in all_features[1:]:\n",
    "            shared_features &= set(features.keys())\n",
    "        \n",
    "        # Find common positive features\n",
    "        common_positive = []\n",
    "        for feature in shared_features:\n",
    "            if all(f[feature] == 1 for f in all_features):\n",
    "                common_positive.append(feature)\n",
    "        \n",
    "        print(f\"   Common positive features ({len(common_positive)}):\")\n",
    "        if common_positive:\n",
    "            # Show first 5 features\n",
    "            shown = common_positive[:5]\n",
    "            print(f\"     {', '.join(shown)}\")\n",
    "            if len(common_positive) > 5:\n",
    "                print(f\"     ... and {len(common_positive) - 5} more\")\n",
    "        else:\n",
    "            print(\"     None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Notes\n",
    "\n",
    "### Caching Strategy\n",
    "\n",
    "The distances module uses multiple levels of caching:\n",
    "\n",
    "- **Function-level caching**: `calculate_distance()` uses `@lru_cache(maxsize=4096)`\n",
    "- **Feature caching**: Features are cached by the features module\n",
    "- **Matrix caching**: `build_distance_matrix()` can optionally use cached calculations\n",
    "\n",
    "### Memory Usage\n",
    "\n",
    "- Distance matrices are stored as `float64` numpy arrays\n",
    "- For N phonemes, matrix requires 8*N² bytes\n",
    "- Large matrices (N>1000) may require significant memory\n",
    "- Consider computing distances on-demand for very large sets\n",
    "\n",
    "### Numerical Stability\n",
    "\n",
    "- All methods handle edge cases (zero vectors, identical vectors)\n",
    "- Cosine distance includes special handling for floating-point precision\n",
    "- Normalization prevents overflow in large feature spaces\n",
    "- K-means clustering uses fixed random seed for reproducibility\n",
    "\n",
    "### Extension Points\n",
    "\n",
    "The module provides several ways to extend functionality:\n",
    "\n",
    "1. **Custom distance methods** via `register_distance_method()`\n",
    "2. **Custom normalization** by modifying normalization parameters\n",
    "3. **Alternative clustering** by replacing k-means with other algorithms\n",
    "4. **Parallel computation** by batching matrix calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Also\n",
    "\n",
    "- **[Features Module API](features.ipynb)**: Core phonetic feature extraction\n",
    "- **[Implementation Details](../chapters/03_implementation.ipynb)**: Internal architecture and algorithms\n",
    "- **[Validation](../chapters/04_validation.ipynb)**: Testing and validation of distance methods\n",
    "- **[User Guide](../chapters/01_quickstart.ipynb)**: Getting started with distfeat\n",
    "\n",
    "## References\n",
    "\n",
    "- **Distance Metrics**: Comprehensive survey of distance measures in pattern recognition\n",
    "- **Phonetic Distance**: Kondrak (2000), McMahon & McMahon (2005)\n",
    "- **Feature Geometry**: Clements & Hume (1995), Hall (2007)\n",
    "- **Clustering**: Hastie et al. (2009), Bishop (2006)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}